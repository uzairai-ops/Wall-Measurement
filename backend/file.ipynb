{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4b09d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/trained_yolo_models/best.pt\"  \n",
    "model = YOLO(model_path)\n",
    "print(f\"YOLOv8 model loaded from: {model_path}\")\n",
    "print(f\"Model classes: {model.names}\")\n",
    "\n",
    "sam_checkpoint_path = \"/content/segment-anything/sam_vit_h.pth\"\n",
    "\n",
    "if not os.path.exists(sam_checkpoint_path):\n",
    "    print(\"Downloading SAM checkpoint...\")\n",
    "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O /content/sam_vit_h_4b8939.pth\n",
    "    print(\"SAM checkpoint downloaded\")\n",
    "\n",
    "# Load SAM model\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint_path)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam.to(device=device)\n",
    "\n",
    "# Create SAM predictor\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "print(f\"SAM model loaded on device: {device}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Test Wall Detection on a Sample Image\n",
    "# =============================================================================\n",
    "\n",
    "# Let's test on a sample from your validation set first\n",
    "import glob\n",
    "\n",
    "# Get a test image from your dataset\n",
    "test_images = glob.glob(\"/content/obj (37).jpeg\")\n",
    "if not test_images:\n",
    "    test_images = glob.glob(\"/content/obj (37).jpeg\")\n",
    "\n",
    "if test_images:\n",
    "    test_image_path = test_images[0]  # Take first image\n",
    "    print(f\"ğŸ–¼ï¸ Testing on: {test_image_path}\")\n",
    "else:\n",
    "    print(\"âŒ No test images found. Upload one manually:\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    test_image_path = list(uploaded.keys())[0]\n",
    "\n",
    "# Load and display image\n",
    "image = cv2.imread(test_image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "print(f\"ğŸ“ Image shape: {image.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Run Wall Detection\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ” Running wall detection...\")\n",
    "\n",
    "# Run YOLOv8 prediction\n",
    "results = model.predict(test_image_path, conf=0.3, save=False, verbose=False)\n",
    "\n",
    "# Extract results\n",
    "detections = []\n",
    "wall_detections = []\n",
    "\n",
    "if results[0].boxes is not None:\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        class_id = int(classes[i])\n",
    "        class_name = model.names[class_id]\n",
    "        detection = {\n",
    "            'bbox': boxes[i],\n",
    "            'score': scores[i],\n",
    "            'class_id': class_id,\n",
    "            'class_name': class_name\n",
    "        }\n",
    "        detections.append(detection)\n",
    "        \n",
    "        # Collect wall detections specifically\n",
    "        if class_name == 'wall':\n",
    "            wall_detections.append(detection)\n",
    "\n",
    "print(f\"âœ… Total detections: {len(detections)}\")\n",
    "print(f\"ğŸ  Wall detections: {len(wall_detections)}\")\n",
    "\n",
    "# Print all detections\n",
    "for det in detections:\n",
    "    print(f\"   {det['class_name']}: {det['score']:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FIXED: Visualization with Proper Color Format\n",
    "# =============================================================================\n",
    "\n",
    "# Visualize all detections (FIXED COLOR ISSUE)\n",
    "image_with_boxes = image_rgb.copy()\n",
    "\n",
    "for i, det in enumerate(detections):\n",
    "    x1, y1, x2, y2 = det['bbox'].astype(int)\n",
    "    \n",
    "    # FIXED: Use proper color format for OpenCV (BGR format as tuples)\n",
    "    if det['class_name'] == 'wall':\n",
    "        color = (255, 0, 0)  # Red for walls\n",
    "        thickness = 3\n",
    "    else:\n",
    "        # Different colors for different classes\n",
    "        colors = [(0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), \n",
    "                 (0, 255, 255), (128, 128, 0), (128, 0, 128), (0, 128, 128)]\n",
    "        color = colors[det['class_id'] % len(colors)]\n",
    "        thickness = 2\n",
    "    \n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    # Add label with better formatting\n",
    "    label = f\"{det['class_name']}: {det['score']:.2f}\"\n",
    "    cv2.putText(image_with_boxes, label, (x1, y1-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(image_with_boxes)\n",
    "plt.title(f\"All Detections ({len(detections)} objects)\")\n",
    "plt.axis('off')\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: Focus on Wall Segmentation with SAM\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ¯ Processing walls with SAM...\")\n",
    "\n",
    "# Set image for SAM\n",
    "predictor.set_image(image_rgb)\n",
    "\n",
    "wall_segments = []\n",
    "if wall_detections:\n",
    "    for i, wall_det in enumerate(wall_detections):\n",
    "        print(f\"   Processing wall {i+1}/{len(wall_detections)}\")\n",
    "        \n",
    "        # Use wall bounding box as prompt for SAM\n",
    "        x1, y1, x2, y2 = wall_det['bbox'].astype(int)\n",
    "        input_box = np.array([[x1, y1, x2, y2]])\n",
    "        \n",
    "        # Get SAM segmentation\n",
    "        masks, scores, logits = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        \n",
    "        wall_segments.append({\n",
    "            'mask': masks[0],\n",
    "            'sam_score': scores[0],\n",
    "            'yolo_score': wall_det['score'],\n",
    "            'bbox': wall_det['bbox'],\n",
    "            'wall_id': i+1\n",
    "        })\n",
    "\n",
    "print(f\"âœ… Processed {len(wall_segments)} wall segments\")\n",
    "\n",
    "# Visualize wall segments\n",
    "if wall_segments:\n",
    "    # Create combined wall mask\n",
    "    combined_wall_mask = np.zeros((image_rgb.shape[0], image_rgb.shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    for i, segment in enumerate(wall_segments):\n",
    "        combined_wall_mask[segment['mask']] = (i + 1) * 80\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(combined_wall_mask, cmap='viridis')\n",
    "    plt.title(f\"Wall Segments ({len(wall_segments)} walls)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ADDED: Create detailed overlay visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Show original with wall masks overlay\n",
    "    overlay = image_rgb.copy()\n",
    "    colors = [(255, 100, 100), (100, 255, 100), (100, 100, 255), (255, 255, 100)]\n",
    "    \n",
    "    for i, segment in enumerate(wall_segments):\n",
    "        mask = segment['mask']\n",
    "        color = colors[i % len(colors)]\n",
    "        overlay[mask] = overlay[mask] * 0.6 + np.array(color) * 0.4\n",
    "        \n",
    "        # Add wall number on the mask\n",
    "        mask_coords = np.where(mask)\n",
    "        if len(mask_coords[0]) > 0:\n",
    "            center_y, center_x = np.mean(mask_coords[0]), np.mean(mask_coords[1])\n",
    "            cv2.putText(overlay, f\"Wall {i+1}\", (int(center_x)-30, int(center_y)), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    \n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"Walls with Segmentation Masks\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.text(0.5, 0.5, \"No walls detected\", ha='center', va='center', fontsize=16)\n",
    "    plt.title(\"No Wall Segments\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: Enhanced Measurement Preparation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š WALL MEASUREMENT ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if wall_segments:\n",
    "    for i, segment in enumerate(wall_segments):\n",
    "        mask = segment['mask']\n",
    "        bbox = segment['bbox']\n",
    "        \n",
    "        # Calculate measurements\n",
    "        mask_area_pixels = np.sum(mask)\n",
    "        bbox_width = bbox[2] - bbox[0]\n",
    "        bbox_height = bbox[3] - bbox[1]\n",
    "        bbox_area = bbox_width * bbox_height\n",
    "        coverage = mask_area_pixels / bbox_area if bbox_area > 0 else 0\n",
    "        \n",
    "        print(f\"\\nğŸ  Wall {i+1}:\")\n",
    "        print(f\"   YOLO confidence: {segment['yolo_score']:.3f}\")\n",
    "        print(f\"   SAM score: {segment['sam_score']:.3f}\")\n",
    "        print(f\"   Bounding box: [{bbox[0]:.0f}, {bbox[1]:.0f}, {bbox[2]:.0f}, {bbox[3]:.0f}]\")\n",
    "        print(f\"   Dimensions: {bbox_width:.0f} Ã— {bbox_height:.0f} pixels\")\n",
    "        print(f\"   Mask area: {mask_area_pixels:,} pixels\")\n",
    "        print(f\"   Coverage: {coverage:.1%}\")\n",
    "        \n",
    "        # ENHANCED: Better quality assessment\n",
    "        if segment['yolo_score'] > 0.7 and segment['sam_score'] > 0.9:\n",
    "            quality = \"ğŸ† EXCELLENT\"\n",
    "        elif segment['yolo_score'] > 0.5 and segment['sam_score'] > 0.8:\n",
    "            quality = \"âœ… GOOD\"\n",
    "        elif segment['yolo_score'] > 0.3 and segment['sam_score'] > 0.6:\n",
    "            quality = \"âš ï¸  MODERATE\"\n",
    "        else:\n",
    "            quality = \"âŒ POOR\"\n",
    "        \n",
    "        print(f\"   Quality: {quality}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ SUCCESS! Your pipeline detected and segmented {len(wall_segments)} walls!\")\n",
    "    print(\"ğŸ“ Ready for the next step: DEPTH ESTIMATION\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No walls detected!\")\n",
    "    print(\"ğŸ’¡ Try:\")\n",
    "    print(\"   - Lower confidence threshold (conf=0.1)\")\n",
    "    print(\"   - Different test image with clear walls\")\n",
    "    print(\"   - Check if image has good lighting\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: Pipeline Status and Next Steps\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nğŸš€ PIPELINE STATUS:\")\n",
    "print(\"=\"*40)\n",
    "print(\"âœ… 1. YOLOv8 wall detection - WORKING\")\n",
    "print(\"âœ… 2. SAM segmentation - WORKING\")\n",
    "print(\"ğŸ”„ 3. Next: Add depth estimation\")\n",
    "print(\"ğŸ”„ 4. Next: Camera calibration\") \n",
    "print(\"ğŸ”„ 5. Next: Real-world measurements\")\n",
    "\n",
    "if wall_segments:\n",
    "    print(f\"\\nğŸ‰ EXCELLENT PROGRESS!\")\n",
    "    print(\"Your pipeline is working correctly! Wall detection and segmentation are successful.\")\n",
    "    print(\"Ready to proceed with depth estimation for measurement calculation.\")\n",
    "    \n",
    "    # ADDED: Preparation for next steps\n",
    "    print(f\"\\nğŸ“‹ Ready for Integration:\")\n",
    "    print(f\"   - Wall segments: {len(wall_segments)} found\")\n",
    "    print(f\"   - Average YOLO confidence: {np.mean([s['yolo_score'] for s in wall_segments]):.3f}\")\n",
    "    print(f\"   - Average SAM score: {np.mean([s['sam_score'] for s in wall_segments]):.3f}\")\n",
    "    print(f\"   - Image resolution: {image.shape[1]}x{image.shape[0]}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Need to improve wall detection before proceeding.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
